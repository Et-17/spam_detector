This is a sample implementation of a Naive Bayes Classifier. You can find the training data in `data/subject_lines.train` and the testing data is `data/subject_lines.test`. I have used an 80/20 split between the training data and the testing data. All of the subject lines come from the Enron spam dataset. This dataset included full emails, but the assignment specifically uses just the subject lines, so I have extracted those from it.

Running `naive_bayes_classifier.py` will run the classifier. First the script will go through the training data and find what words there are, how often those words are used in total, and how often they are used specifically in spam. Next it will calculate the probability that each word would appear in a spam subject line and in a ham subject line. Finally, it will make attempt to predict the classification of each entry in the testing data and print out various stats: currently the confusion matrix, precision, recall, and the F1 score. It will also output all of the guesses and actual answers in `data/predictions.csv` for further analysis.
